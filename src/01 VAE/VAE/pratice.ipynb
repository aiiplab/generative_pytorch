{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c2638d97",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import Lib\n",
    "import os\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from tqdm import tqdm\n",
    "from torch.utils.data import DataLoader\n",
    "from torchvision.utils import make_grid\n",
    "from torchvision.datasets import MNIST"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "adf3bbe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setting hyper-params\n",
    "device = \"cuda\"\n",
    "batch_size = 128\n",
    "lr = 1e-03\n",
    "epochs = 20\n",
    "\n",
    "in_channels = 1\n",
    "z_dim = 128\n",
    "hidden_dims = [32, 64]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "863d3a0b",
   "metadata": {},
   "source": [
    "### Step 1. Define Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84c520db",
   "metadata": {},
   "outputs": [],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor()\n",
    "])\n",
    "\n",
    "train_dataset = MNIST(root = \".\", train = True, transform = transform, download = True)\n",
    "test_dataset = MNIST(root = \".\", train = False, transform = transform, download = True)\n",
    "\n",
    "train_loader = DataLoader(train_dataset, batch_size = batch_size, shuffle = True)\n",
    "test_loader = DataLoader(test_dataset, batch_size = batch_size, shuffle = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1474f7d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, labels = next(iter(train_loader))\n",
    "\n",
    "print(\"Images shape: {}\".format(images.shape))\n",
    "print(\"labels shape: {}\".format(labels.shape))\n",
    "\n",
    "grid = make_grid(images[:64], nrow = 8, normalize=True)\n",
    "\n",
    "plt.figure(figsize = (12, 12))\n",
    "plt.imshow(grid[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74bbbc25",
   "metadata": {},
   "source": [
    "### Step 2. Defien Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27c6de4",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Upsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, scale_factor=2, mode=\"nearest\"):\n",
    "        super().__init__()\n",
    "        self.up = nn.Sequential(\n",
    "            nn.Upsample(scale_factor=scale_factor, mode=mode),\n",
    "            nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=1, padding=1))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.up(x)\n",
    "\n",
    "\n",
    "class Downsample(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, kernel_size=3, stride=2, padding=1):\n",
    "        super().__init__()\n",
    "        self.down = nn.Conv2d(in_channels, out_channels, kernel_size, stride, padding)\n",
    "\n",
    "    def forward(self, x):\n",
    "        return self.down(x)\n",
    "\n",
    "\n",
    "class VAE(nn.Module):\n",
    "    def __init__(self, in_channels=1, z_dim=128, hidden_dims=[32, 64]):\n",
    "        super().__init__()\n",
    "        # Encoder\n",
    "        self.encoder = nn.Sequential(\n",
    "            Downsample(in_channels, hidden_dims[0]),\n",
    "            nn.BatchNorm2d(hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            Downsample(hidden_dims[0], hidden_dims[1]),\n",
    "            nn.BatchNorm2d(hidden_dims[1]),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.flatten = nn.Flatten()\n",
    "        self.fc_mu = nn.Linear(64*7*7, z_dim)\n",
    "        self.fc_logvar = nn.Linear(64*7*7, z_dim)\n",
    "\n",
    "        # Decoder\n",
    "        self.decoder_input = nn.Linear(z_dim, 64*7*7)\n",
    "\n",
    "        self.decoder = nn.Sequential(\n",
    "            Upsample(hidden_dims[1], hidden_dims[0]),\n",
    "            nn.BatchNorm2d(hidden_dims[0]),\n",
    "            nn.ReLU(),\n",
    "            Upsample(hidden_dims[0], in_channels),\n",
    "            nn.Sigmoid() # value to [0, 1]\n",
    "        )\n",
    "\n",
    "    def reparameterize(self, mu, logvar):\n",
    "        sigma = torch.exp(0.5 * logvar)\n",
    "        eps = torch.randn_like(sigma).to(logvar.device)\n",
    "        return mu + sigma * eps\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.flatten(x)\n",
    "        mu = self.fc_mu(x)\n",
    "        logvar = self.fc_logvar(x)\n",
    "        return mu, logvar\n",
    "\n",
    "    def decode(self, z):\n",
    "        z = self.decoder_input(z)\n",
    "        z = z.view(-1, 64, 7, 7)\n",
    "        out = self.decoder(z)\n",
    "        return out\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self.reparameterize(mu, logvar)\n",
    "        out = self.decode(z)\n",
    "        return out, mu, logvar\n",
    "\n",
    "x = torch.randn(4, 1, 28, 28)\n",
    "model = VAE(in_channels=in_channels, z_dim=z_dim)\n",
    "recon_x, _, _ = model(x)\n",
    "print(\"x:\", x.shape, \"recon_x:\", recon_x.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e88209bb",
   "metadata": {},
   "source": [
    "### Step 3. Define Loss function and Model & Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37156138",
   "metadata": {},
   "outputs": [],
   "source": [
    "# loss function\n",
    "def loss_function(pred, target, mu, logvar):\n",
    "    recon_loss = F.binary_cross_entropy(pred, target, reduction=\"mean\")\n",
    "    kl_loss = -0.5 * torch.mean(1 + logvar - mu.pow(2) - logvar.exp())\n",
    "    return recon_loss + kl_loss\n",
    "    \n",
    "model = VAE(in_channels=in_channels, z_dim=z_dim, hidden_dims=hidden_dims).to(device) # model\n",
    "optimizer = optim.Adam(model.parameters(), lr=lr) # optimizer"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "37cdb88d",
   "metadata": {},
   "source": [
    "### Step 4. Train VAE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3949c4c4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_epoch(model, dataloader, criterion, optimizer, epoch, device):\n",
    "    total = 0\n",
    "    total_loss = 0.\n",
    "\n",
    "    model.train()\n",
    "    for batch_idx, (data, _) in enumerate(dataloader):\n",
    "        data = data.to(device)\n",
    "        total += data.size(0)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        out, mu, logvar = model(data)\n",
    "        loss = criterion(out, data, mu, logvar)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        total_loss += loss.item()\n",
    "\n",
    "        if batch_idx % 100 == 0:\n",
    "            print(f\"[Train] Epoch {epoch} [{total}/{len(dataloader.dataset)}]\\tAvg Loss: {total_loss/(batch_idx+1):.5f}\")\n",
    "\n",
    "    # Sample plot\n",
    "    plt.figure(figsize=(6,6))\n",
    "    sample = out[0].permute(1, 2, 0).detach().cpu().numpy()\n",
    "    plt.imshow(sample)\n",
    "    plt.axis(\"off\")\n",
    "    plt.show()\n",
    "    plt.close()\n",
    "\n",
    "    total_loss /= len(dataloader)\n",
    "    return total_loss\n",
    "\n",
    "for epoch in range(1, epochs+1):\n",
    "    train_loss = train_epoch(model, train_loader, loss_function, optimizer, epoch, device)\n",
    "    print(f\"[Train] Epoch: {epoch}\\tTotal Avg Loss: {train_loss:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42bc3ac6",
   "metadata": {},
   "source": [
    "### Step 5. Generate Images from Test Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4d997829",
   "metadata": {},
   "outputs": [],
   "source": [
    "images, label = next(iter(test_loader))\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    images = images.to(device)\n",
    "    recon_images, _, _ = model(images)\n",
    "\n",
    "recon_grid = make_grid(recon_images[:64].detach().cpu(), nrow = 8, normalize=True)\n",
    "gt_grid = make_grid(images[:64].detach().cpu(), nrow = 8, normalize=True)\n",
    "\n",
    "fig, ax = plt.subplots(nrows=1, ncols=2, figsize = (18, 9))\n",
    "ax[0].imshow(recon_grid[0])\n",
    "ax[0].set_title(\"Generation\")\n",
    "ax[0].set_axis_off()\n",
    "\n",
    "ax[1].imshow(gt_grid[0])\n",
    "ax[1].set_title(\"Ground Truth\")\n",
    "ax[1].set_axis_off()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed7f50e6",
   "metadata": {},
   "source": [
    "### Step 6. Generate Images from Noise vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c351d478",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(batch_size, z_dim).to(device)\n",
    "\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    generated_images = model.decode(noise)\n",
    "\n",
    "grid = make_grid(generated_images[:64].detach().cpu(), nrow = 8, normalize=True)\n",
    "plt.figure(figsize = (12, 12))\n",
    "plt.imshow(grid[0])\n",
    "plt.axis(\"off\")\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "gyuseok",
   "language": "python",
   "name": "gyuseok"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
